# Анализ публикаций в Scopus с использованием Scopus API

## Структура проекта

* scopusCrawler/APIScopusCrawler - модуль API (выгружает данные с API, очищает и загружает в базу данных).
* scopusCrawler/WebScopusCrawler - модуль Web (выгружает данные с сайта SCOPUS, очищает и загружает в базу данных).

## Установка и запуск

**Требования для установки и запуска**: 
* docker
* docker-compose
* git

Описанные действия выполнялись на операционной системе Ubuntu 22.04
* Клонировать репозиторий: https://github.com/KorolevDenis/BIGDATA_2022
* Перейти в директорию проекта: cd ~/BIGDATA_2022/scopusCrawler
* Установить зависимости из файла requirements.txt
* Для запуска API модуля:
  * Перейти в директорию: cd ~/BIGDATA_2022/scopusCrawler/APIScopusCrawler
  * Выполнить: tmux
  * Выполнить: scrapyd > scrapyd.log &
  * Нажать комбинацию клавиш CNTRL и b и затем нажать d
  * Запустить скрипт: python year_run.py
    Этот скрипт запускает scrapy процессы для каждого года из промежутка, переданного параметрами. Принимает на вход 3 параметра:
    * левая граница промежутка годов (включая левую границу)
    * правая граница промежутка годов (не включая праваю границу)
    * количество потоков (не включая праваю границу)

Основные переменные окружения доступны в файле .env.
